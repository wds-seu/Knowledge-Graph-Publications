# Reasoning Like Human: Hierarchical Reinforcement Learning for Knowledge Graph Reasoning
* **author**: Guojia Wan, Shirui Pan, Chen Gong, Chuan Zhou, Gholamreza Haffari
* **abstract**: Knowledge Graphs typically suffer from incompleteness. A popular approach to knowledge graph completion is to infer missing knowledge by multihop reasoning over the information found along other paths connecting a pair of entities. However, multi-hop reasoning is still challenging because the reasoning process usually experiences multiple semantic issue that a relation or an entity has multiple meanings. In order to deal with the situation, we propose a novel Hierarchical Reinforcement Learning framework to learn chains of reasoning from a Knowledge Graph automatically. Our framework is inspired by the hierarchical structure through which human handle cognitionally ambiguous cases. The whole reasoning process is decomposed into a hierarchy of two-level Reinforcement Learning policies for encoding historical information and learning structured action space. As a consequence, it is more feasible and natural for dealing with the multiple semantic issue. Experimental results show that our proposed model achieves substantial improvements in ambiguous relation tasks.
* **keywords**: Hierarchical Reinforcement Learning, Knowledge Graph Reasoning
* **interpretation**: [来源: 暂无]()
* **pdf**: [link](https://www.ijcai.org/Proceedings/2020/267)
* **code**:
* **dataset**: NELL995, FB15K-237, WN18RR
* **ppt/video**:
* **curation**: Jiong Zhang 