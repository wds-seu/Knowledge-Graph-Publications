#  Multi-Cell Compositional LSTM for NER Domain Adaptation

* **author**: Chen Jia, Yue Zhang
* **abstract**:Cross-domain NER is a challenging yet practical problem. Entity mentions can be highly different across domains. However, the correlations between entity types can be relatively more stable across domains. We investigate a multi-cell compositional LSTM structure for multi-task learning, modeling each entity type using a separate cell state. With the help of entity typed units, cross-domain knowledge transfer can be made in an entity type level. Theoretically, the resulting distinct feature distributions for each entity type make it more powerful for cross-domain transfer. Empirically, experiments on four few-shot and zeroshot datasets show our method significantly outperforms a series of multi-task learning
  methods and achieves the best results.
* **keywords**:
* **interpretation**:
* **pdf**:[link](https://www.aclweb.org/anthology/2020.acl-main.524.pdf)
* **code**:[github](https://github.com/jiachenwestlake/Multi-Cell_LSTM)
* **dataset**: SDAï¼ŒUDA
* **ppt/video**:
* **curator**:Shuwei Yuan