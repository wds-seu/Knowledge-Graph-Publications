# Improving Neural Fine-Grained Entity Typing With Knowledge Attention
* **author**: Ji Xin, Yankai Lin, Zhiyuan Liu, Maosong Sun
* **abstract**: Fine-grained entity typing aims to identify the semantic type of an entity in a particular plain text. It is an important task which can be helpful for a lot of natural language processing (NLP) applications. Most existing methods typically extract features separately from the entity mention and context words for type classification. These methods inevitably fail to model complex correlations between entity mentions and context words. They also neglect rich background information about these entities in knowledge bases (KBs). To address these issues, we take information from KBs into consideration to bridge entity mentions and their context together, and thereby propose Knowledge-Attention Neural Fine-Grained Entity Typing. Experimental results and case studies on real-world datasets demonstrate that our model significantly outperforms other state-of-the-art methods, revealing the effectiveness of incorporating KB information for entity typing. Code and data for this paper can be found at https://github.com/thunlp/KNET.
* **keywords**: Entity Typing; Attention
* **interpretation**: [来源: ]()
* **pdf**: [link]()
* **code**: [link]()
* **dataset**:
* **ppt/video**:
* **curation**: Jiong Zhang 
